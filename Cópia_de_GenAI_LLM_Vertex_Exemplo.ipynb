{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digo-luz/AI-Dev-Scripts/blob/main/C%C3%B3pia_de_GenAI_LLM_Vertex_Exemplo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Nota: Pode ser necessário reiniciar o kernel depois de instalar algum pacote"
      ],
      "metadata": {
        "id": "SIbfRqUYifsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "import json\n",
        "import requests"
      ],
      "metadata": {
        "id": "WoIzyOUMk-QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Gen AI SDK documentation:  \n",
        "https://googleapis.github.io/python-genai/"
      ],
      "metadata": {
        "id": "S1uHwqHBp1q3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autenticação e teste de conectividade"
      ],
      "metadata": {
        "id": "Ar4z34GhioZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "H8S21r_ch-NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preenchimento do código do projeto\n",
        "#@markdown Preencha abaixo o código do teu projeto na GCP. <br/>\n",
        "#@markdown Após preenchimento do código, execute essa célula.   <br/>\n",
        "\n",
        "project_id = \"autobsg\"  #@param {type: \"string\"}\n",
        "location = \"us-central1\"  #@param {type: \"string\"}\n",
        "\n",
        "llm_model = \"gemini-2.0-flash-lite-001\" # @param [\"gemini-2.0-flash-001\",\"gemini-2.0-flash-lite-001\",\"gemini-1.5-flash-002\"] {\"allow-input\":true}\n",
        "#@markdown ---\n",
        "llm_client = genai.Client( vertexai=True, project=project_id, location=location, )"
      ],
      "metadata": {
        "id": "hqIzr5Rbix_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 - Exemplo simples: Hello World"
      ],
      "metadata": {
        "id": "lk3HUaWCjF7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A ) Parâmetros de configuração da chamada do modelo, incluindo instruções sistêmicas sobre a saída do modelo.  \n",
        "Para saber sobre os parâmetros existentes atualmente, segue link da documentação:  \n",
        "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters?hl=pt-br"
      ],
      "metadata": {
        "id": "KAgvH_6ht99c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_agent_config = types.GenerateContentConfig(\n",
        "    candidate_count = 1,\n",
        "    temperature = 0.6,\n",
        "    top_p = 1,\n",
        "    top_k = 40,\n",
        "    max_output_tokens = 2048,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    safety_settings = [types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=types.HarmBlockThreshold.BLOCK_NONE),\n",
        "                       types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=types.HarmBlockThreshold.BLOCK_ONLY_HIGH),\n",
        "                       types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=types.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE),\n",
        "                       types.SafetySetting(category=types.HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=types.HarmBlockThreshold.OFF),\n",
        "                       ],\n",
        "    response_mime_type = \"application/json\",\n",
        "    system_instruction=\n",
        "          [\n",
        "            'Você é um galanteador brasileiro e deve responder em português, mesmo que seja solicitado para que a resposta seja em outra língua.',\n",
        "            'Sua missão é fazer piadas de duplo sentido sem conotação sexual.'\n",
        "          ],\n",
        "    response_schema = {\"type\":\"OBJECT\",\"properties\":{\"retorno_do_modelo\":{\"type\":\"STRING\"}}},\n",
        ")"
      ],
      "metadata": {
        "id": "F0wnuJhzlQFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B ) Entrada do modelo, também conhecido como request ou request contents.  \n",
        "Nota, estamos usando uma versão super simplificada com\n",
        "\n",
        "```\n",
        "contents = \"Me fale sobre os Lusíadas.\"\n",
        "```\n",
        "\n",
        "Por usar apenas parâmetros padrão, a criação desse `contents` seria equivalente a esse:  \n",
        "```\n",
        "contents = []\n",
        "content = types.Content(\n",
        "    role=\"user\", # Role must be either ‘user’ or ‘model’. Useful to set for multi-turn conversations, otherwise can be left blank or unset. If role is not specified, SDK will determine the role.\n",
        "    parts=[\n",
        "        types.Part.from_text(text=\"\"\"Me fale sobre os Lusíadas.\"\"\")\n",
        "    ]\n",
        ")\n",
        "contents.append(content)\n",
        "```"
      ],
      "metadata": {
        "id": "17w3k6mJtu-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contents = 'Me fale sobre os Lusíadas.'"
      ],
      "metadata": {
        "id": "q4v6juM6qO_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C ) Chama e obtém o retorno do modelo. Usando o SDK, o mesmo vem em um objeto estruturado do tipo `google.genai.types.GenerateContentResponse`"
      ],
      "metadata": {
        "id": "27Not5hWuntN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_ret = llm_client.models.generate_content(\n",
        "  model = llm_model,\n",
        "  contents = contents,\n",
        "  config = llm_agent_config,\n",
        "  )\n",
        "display(llm_ret)"
      ],
      "metadata": {
        "id": "xQxriOS1r3WM",
        "outputId": "f2c22e03-bd0d-44b2-ef84-54c4d8d97b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"retorno_do_modelo\": \"Ah, os Lusíadas! Uma epopeia que é um verdadeiro \\\\\"tesouro\\\\\" da literatura portuguesa. Sabe, ela é tão \\\\\"profunda\\\\\" que até hoje a gente se \\\\\"afoga\\\\\" em suas palavras. Mas, falando sério, é uma obra que nos leva a \\\\\"navegar\\\\\" por histórias incríveis, cheias de \\\\\"descobertas\\\\\" e \\\\\"aventuras\\\\\".\"\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.3107082894507875, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=[SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=1.224453e-06, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=None), SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=3.5736003e-10, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=0.027134024), SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=1.0685059e-05, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=None), SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=3.739578e-09, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=None)])], create_time=datetime.datetime(2025, 3, 11, 0, 1, 13, 329523, tzinfo=TzInfo(UTC)), response_id='SX3PZ7OOFNmbm9IP3d77kAE', model_version='gemini-2.0-flash-lite-001', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=94, prompt_token_count=54, total_token_count=148), automatic_function_calling_history=[], parsed={'retorno_do_modelo': 'Ah, os Lusíadas! Uma epopeia que é um verdadeiro \"tesouro\" da literatura portuguesa. Sabe, ela é tão \"profunda\" que até hoje a gente se \"afoga\" em suas palavras. Mas, falando sério, é uma obra que nos leva a \"navegar\" por histórias incríveis, cheias de \"descobertas\" e \"aventuras\".'})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_ret.text)"
      ],
      "metadata": {
        "id": "4ADrM0dBrvTW",
        "outputId": "8c28c8e5-a252-4ad0-8d7f-e4c64bee1c61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"retorno_do_modelo\": \"Ah, os Lusíadas! Uma epopeia que é um verdadeiro \\\"tesouro\\\" da literatura portuguesa. Sabe, ela é tão \\\"profunda\\\" que até hoje a gente se \\\"afoga\\\" em suas palavras. Mas, falando sério, é uma obra que nos leva a \\\"navegar\\\" por histórias incríveis, cheias de \\\"descobertas\\\" e \\\"aventuras\\\".\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 - Exemplo com saída em JSON estruturado."
      ],
      "metadata": {
        "id": "T5w0Qsu-j64-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sobreescreve o Guard Rail da estrutura de resposta."
      ],
      "metadata": {
        "id": "603lpu2TJiHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_agent_config.response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"n1\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"n2\": {\n",
        "      \"type\": \"integer\"\n",
        "    },\n",
        "    \"senna\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"piada\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"extra\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  },\n",
        "  \"required\": [\n",
        "    \"n1\",\n",
        "    \"n2\",\n",
        "    \"senna\",\n",
        "    \"piada\"\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "pvZphr0zyc85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, o `contents` será um prompt simples."
      ],
      "metadata": {
        "id": "jFlBbqs-J9Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contents = \"\"\"Retorne um json contendo o seguinte conteúdo:\n",
        "- n1: Um número aleatório entre 1 e 1000;\n",
        "- n2: Um número primo maior que 100;\n",
        "- senna: A data de nascimento do Ayrton Senna no formato dd-MM-YYYY;\n",
        "- piada: Um texto com uma piada sobre alunos e professores.\"\"\""
      ],
      "metadata": {
        "id": "M9GVMBf1hyq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_ret = llm_client.models.generate_content(\n",
        "  model = llm_model,\n",
        "  contents = contents,\n",
        "  config = llm_agent_config,\n",
        "  )\n",
        "display(llm_ret)"
      ],
      "metadata": {
        "id": "Bt2I3Kg2xzm9",
        "outputId": "b6c07a87-69d4-4a7a-afb7-55cce4ce5992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='{\\n  \"n1\": 427,\\n  \"n2\": 101,\\n  \"piada\": \"Por que o professor de matemática sempre anda com a cara fechada? Porque ele vive com problemas!\",\\n  \"senna\": \"21-03-1960\"\\n}')], role='model'), citation_metadata=None, finish_message=None, token_count=None, avg_logprobs=-0.11931957517351423, finish_reason=<FinishReason.STOP: 'STOP'>, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=[SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 'HARM_CATEGORY_HATE_SPEECH'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=1.0148615e-05, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=None), SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 'HARM_CATEGORY_DANGEROUS_CONTENT'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=3.345629e-08, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=0.0050497353), SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_HARASSMENT: 'HARM_CATEGORY_HARASSMENT'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=0.0004443918, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=None), SafetyRating(blocked=None, category=<HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 'HARM_CATEGORY_SEXUALLY_EXPLICIT'>, probability=<HarmProbability.NEGLIGIBLE: 'NEGLIGIBLE'>, probability_score=6.716037e-09, severity=<HarmSeverity.HARM_SEVERITY_NEGLIGIBLE: 'HARM_SEVERITY_NEGLIGIBLE'>, severity_score=0.031476676)])], create_time=datetime.datetime(2025, 3, 11, 0, 1, 23, 42403, tzinfo=TzInfo(UTC)), response_id='U33PZ6PLArTc-O4P2oXxwQY', model_version='gemini-2.0-flash-lite-001', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cached_content_token_count=None, candidates_token_count=70, prompt_token_count=139, total_token_count=209), automatic_function_calling_history=[], parsed={'n1': 427, 'n2': 101, 'piada': 'Por que o professor de matemática sempre anda com a cara fechada? Porque ele vive com problemas!', 'senna': '21-03-1960'})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_ret.text)"
      ],
      "metadata": {
        "id": "VEb4H738x4Nx",
        "outputId": "092a6cc0-fe40-42a9-8395-75a002ebd843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"n1\": 427,\n",
            "  \"n2\": 101,\n",
            "  \"piada\": \"Por que o professor de matemática sempre anda com a cara fechada? Porque ele vive com problemas!\",\n",
            "  \"senna\": \"21-03-1960\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversão de `string` para `json`"
      ],
      "metadata": {
        "id": "ea8fWRl7l5Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_ret = json.loads( llm_ret.text )\n",
        "json_ret"
      ],
      "metadata": {
        "id": "MHvt-xplyMRn",
        "outputId": "ca41e3b8-e025-4033-fdfa-2054b76a0a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n1': 427,\n",
              " 'n2': 101,\n",
              " 'piada': 'Por que o professor de matemática sempre anda com a cara fechada? Porque ele vive com problemas!',\n",
              " 'senna': '21-03-1960'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 - Exemplo com múltiplas entradas estruturadas"
      ],
      "metadata": {
        "id": "oSV-czgn10Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtém um arquivo da internet e armazena seus bytes\n",
        "image_url = \"https://storage.googleapis.com/ds-publico/IA/llminput01.jpeg\"\n",
        "image_bytes = requests.get(image_url).content\n",
        "base64_image = base64.b64encode(image_bytes).decode('utf-8')"
      ],
      "metadata": {
        "id": "Fyp7I7aJ27k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents = [\n",
        "  types.Content(\n",
        "    role=\"user\",\n",
        "    parts=[\n",
        "      types.Part.from_text(text=\"\"\"Me conte uma piada sobre brasileiro em português.\"\"\"),\n",
        "      types.Part.from_bytes(data=image_bytes, mime_type=\"image/jpeg\",),\n",
        "      types.Part.from_text(text=\"\"\"Considere a imagem fornecida para a piada.\"\"\")\n",
        "    ]\n",
        "  )\n",
        "]"
      ],
      "metadata": {
        "id": "XPyI84_U3pOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_ret = llm_client.models.generate_content(\n",
        "  model = llm_model,\n",
        "  contents = contents,\n",
        "  config = llm_agent_config,\n",
        "  )\n",
        "print(llm_ret.text)"
      ],
      "metadata": {
        "id": "EU0fvTnL4nk2",
        "outputId": "4aca26f0-af41-4f3b-9c2d-24f63bdab0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"n1\": 50,\n",
            "  \"n2\": 50,\n",
            "  \"piada\": \"O que o brasileiro foi fazer na escada? Subir na vida!\",\n",
            "  \"senna\": \"Ayrton Senna foi o melhor piloto de todos os tempos.\",\n",
            "  \"extra\": \"O Brasil é um país de gente feliz!\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXERCICIO"
      ],
      "metadata": {
        "id": "EXU0NxlpjPsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A URL a seguir contém o relatório de desempenho do quarto trimestre de 2024 da Petrobrás. Por ser o último trimestre, também é um relatório anual.  \n",
        "\n",
        "\n",
        "URL: https://storage.googleapis.com/ds-publico/IA/petrobras_ri_2024T4_release.pdf\n",
        "\n",
        "\n",
        "Você é um analista do mercado financeiro e deve analisar o mais rápido possível este relatório trimestral / anual.  \n",
        "\n",
        "Considere que deverá retornar um arquivo JSON com a seguinte estrutura exemplo:\n",
        "\n",
        "```\n",
        "{\n",
        "  \"resumo\": Resumo do relatório;\n",
        "  \"opiniao\": Opinião sobre o relatório;\n",
        "  \"classificacao\": positiva, negativa ou neutra sobre o relatório;\n",
        "  \"dividendos\": Se houver, mencionar os dividendos (opcional);\n",
        "  \"faturamento\": Se houver, mencionar o faturamento (opcional);\n",
        "  \"lucro\": Se houver, mencionar o lucro (opcional);\n",
        "  \"extra\": Alguma informação relevante (opcional)\n",
        "}\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "7GgQ09cDSgA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considerações específicas da sua análise:\n",
        "- O Mercado espera uma comparação entre trimestres mais importante do que a comparação anual;\n",
        "- Considere que houve troca de presidente da companhia na opinião fornecida;"
      ],
      "metadata": {
        "id": "G0vQSSM9U6lT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se solicitado, não se esqueça de submeter o Notebook com sua resposta pelo Portal"
      ],
      "metadata": {
        "id": "Pye6fbEkWFk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "8esbg9M98C9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_agent_config.response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"resumo\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"opiniao\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"classificacao\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"dividendos\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"faturamento\": {\n",
        "      \"type\": \"number\"\n",
        "    },\n",
        "    \"lucro\": {\n",
        "      \"type\": \"number\"\n",
        "    },\n",
        "    \"extra\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  },\n",
        "  \"required\": [\n",
        "    \"resumo\",\n",
        "    \"opiniao\",\n",
        "    \"classificacao\",\n",
        "    \"dividendos\",\n",
        "    \"faturamento\",\n",
        "    \"lucro\",\n",
        "    \"extra\"\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "toDya8vbhNqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents = \"\"\"\n",
        "Por favor, analise o relatório, considere o documento fornecido para relatório.\n",
        "\n",
        "Retorne um JSON com a seguinte estrutura:\n",
        "\n",
        "{\n",
        "  \"resumo\": \"Um resumo conciso do relatório, destacando os pontos principais.\",\n",
        "  \"opiniao\": \"Sua opinião sobre o desempenho da Petrobrás neste trimestre, considerando a troca de presidente e o foco do mercado em comparações trimestrais.\",\n",
        "  \"classificacao\": \"Uma classificação geral do relatório: 'positiva', 'negativa' ou 'neutra'.\",\n",
        "  \"dividendos\": \"Informações sobre dividendos anunciados, se houver.\",\n",
        "  \"faturamento\": \"O valor do faturamento da Petrobrás neste trimestre, se disponível.\",\n",
        "  \"lucro\": \"O valor do lucro líquido da Petrobrás neste trimestre, se disponível.\",\n",
        "  \"extra\": \"Quaisquer outras informações relevantes ou observações que você considere importantes.\"\n",
        "}\n",
        "\n",
        "Lembre-se de:\n",
        "\n",
        "* Priorizar a comparação entre o desempenho deste trimestre e o trimestre anterior.\n",
        "* Considerar a mudança na presidência da companhia em sua análise.\n",
        "* As informações sobre dividendos, faturamento e lucro são opcionais, inclua-as apenas se estiverem disponíveis no relatório.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "k0xo7Y7HiGVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtém um arquivo da internet e armazena seus bytes\n",
        "image_url = \"https://storage.googleapis.com/ds-publico/IA/petrobras_ri_2024T4_release.pdf\"\n",
        "image_bytes = requests.get(image_url).content\n",
        "# base64_image = base64.b64encode(image_bytes).decode('utf-8')"
      ],
      "metadata": {
        "id": "dqmW2_lMi-hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents = [\n",
        "  types.Content(\n",
        "    role=\"user\",\n",
        "    parts=[\n",
        "      types.Part.from_text(text=\"\"\"Por favor, analise o relatório.\"\"\"),\n",
        "      types.Part.from_bytes(data=image_bytes, mime_type=\"application/pdf\",),\n",
        "      types.Part.from_text(text=\"\"\"considere o documento fornecido para relatório.\"\"\")\n",
        "    ]\n",
        "  )\n",
        "]"
      ],
      "metadata": {
        "id": "YJ4jpJzHiqGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_ret = llm_client.models.generate_content(\n",
        "  model = llm_model,\n",
        "  contents = contents,\n",
        "  config = llm_agent_config,\n",
        "  )\n",
        "print(llm_ret.text)"
      ],
      "metadata": {
        "id": "Zd89KnaSjWoI",
        "outputId": "59458416-401d-4627-b362-97716eb1760a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"classificacao\": \"Relatório de Desempenho 2024 da Petrobras\",\n",
            "  \"dividendos\": \"A Petrobras distribuiu R$ 102,6 bilhões em dividendos, demonstrando seu compromisso com os investidores.\",\n",
            "  \"extra\": \"O relatório destaca o excelente desempenho financeiro e operacional da Petrobras em 2024, com ênfase na geração de caixa e na redução da dívida.\",\n",
            "  \"faturamento\": 490.829,\n",
            "  \"lucro\": 36.606,\n",
            "  \"opiniao\": \"O relatório apresenta uma visão positiva do desempenho da Petrobras, com foco na geração de valor e no crescimento sustentável.\",\n",
            "  \"resumo\": \"O Relatório de Desempenho 2024 da Petrobras apresenta os resultados financeiros e operacionais da empresa, destacando a geração de caixa, a redução da dívida e os investimentos em novos projetos.\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}